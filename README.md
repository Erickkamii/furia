# ğŸ¤– FURIA Chatbot - Fullstack (Next.js + FastAPI)

Este projeto Ã© um chatbot inteligente para a **FURIA Esports**, com backend em Python (FastAPI) e frontend em Next.js.  
Ele utiliza a API da OpenAI para responder perguntas com base em uma base de conhecimento especÃ­fica da organizaÃ§Ã£o.

---

## ğŸ“ Estrutura do RepositÃ³rio

```
/furia-bot/
â”‚
â”œâ”€â”€ backend/          # Backend com FastAPI
â”‚   â”œâ”€â”€ main.py       # CÃ³digo principal do servidor
â”‚   â””â”€â”€ data/         
â”‚       â””â”€â”€ furia_esports.json  # Base de conhecimento
â”‚
â”œâ”€â”€ frontend/         # Frontend com Next.js
â”‚   â””â”€â”€ ...           
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .env              # Arquivo de variÃ¡veis de ambiente (nÃ£o versionado)
```

---

## âš™ï¸ PrÃ©-requisitos

- Docker instalado: [https://docs.docker.com/get-docker](https://docs.docker.com/get-docker)
- Conta e chave de API da OpenAI: [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)

---

## ğŸš€ Como rodar o projeto

1. Clone o repositÃ³rio:

   ```bash
   git clone https://github.com/seu-usuario/furia-bot.git
   cd furia-bot
   ```

2. Crie um arquivo `.env` na raiz do projeto com o seguinte conteÃºdo:

   ```
   OPENAI_API_KEY=sua-chave-da-openai-aqui
   ```

3. Inicie os serviÃ§os com Docker:

   ```bash
   docker-compose up --build
   ```

4. Acesse:
   - Frontend: http://localhost:3000  
   - Backend (API): http://localhost:8000/health

---

## ğŸ§  Como funciona?

- O **frontend** envia uma pergunta ao backend via `/query`.
- O **backend** lÃª uma base de conhecimento (`furia_esports.json`) com dados da FURIA.
- O backend usa a **OpenAI API** para gerar uma resposta com base no contexto e retorna para o frontend.

---

## ğŸ›  Tecnologias utilizadas

- ğŸ”™ **FastAPI** (Python)
- ğŸŒ **Next.js** (React)
- ğŸ§  **OpenAI API**
- ğŸ³ **Docker + Docker Compose**

---

## ğŸ“„ LicenÃ§a

Este projeto Ã© apenas para fins acadÃªmicos e de demonstraÃ§Ã£o.
